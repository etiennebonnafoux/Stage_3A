\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[a4paper,left=2cm,right=2cm,top=2.5cm,bottom=2cm]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{babel}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{color}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{pifont}

\theoremstyle{plain}% default
\newtheorem{thm}{Théorème}[section]
\newtheorem{lem}[thm]{Lemme}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollaire}
\theoremstyle{definition}
\newtheorem{dfnt}{Définition}[section]
\newtheorem{exmp}{Exemple}[section]
\newtheorem{xca}[exmp]{Exercice}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem*{note}{Note}
\newtheorem{case}{Case}

\crefname{thm}{théorème}{théorèmes}
\crefname{lem}{lemme}{lemmes}
\crefname{prop}{proposition}{propositions}
\crefname{cor}{corollaire}{corollaires}
\crefname{dfnt}{définition}{définitions}
\crefname{exmp}{exemple}{exemples}
\crefname{xca}{exercice}{exercices}
\crefname{rmq}{remarque}{remarques}
\crefname{note}{note}{notes}
\crefname{case}{case}{cases}

\newcommand{\ncref}[1]{\cref{#1} "\nameref{#1}"}
\newcommand{\Ncref}[1]{\Cref{#1} \Nameref{#1}}

\begin{document}

\section{Definition}

\begin{dfnt}
Soit $B=\{(x_1,x_2); 1 \geq x_1 \geq x_2 \geq 0\}$, l'algorithme de Brun est généré par la fonction $T: \to B$ avec
$$
\left \{
\begin{array}{r c }
T(x_1,x_2)=(\frac{1}{x_1}-N,\frac{x_2}{x_1}) \, si \, \frac{1}{x_1}-N \geq \frac{x_2}{x_1} & [j=1] \\
T(x_1,x_2)=(\frac{x_2}{x_1},\frac{1}{x_1}-N) \, si \, \frac{x_2}{x_1} \geq  \frac{1}{x_1}-N & [j=2] \\
N:=[\frac{1}{x_1}]
\end{array}
\right .
$$
\end{dfnt}
En itérant la fonction, nous obtenons une suite de nombre $(x_1^n,x_2^n)$ ainsi que $j(n)$ et $N(n)$.
Nous pouvons alors donner une version plus vectoriel de ce processus allant de l'hyperplan $\mathbb{R}^2 \times \{1 \} $ dans lui même.
$$
\tilde{T}:\begin{pmatrix} 1 \\ x_1^{(n)} \\ x_2^{(n)} \end{pmatrix} \mapsto \begin{pmatrix} 1 \\ x_1^{(n+1)} \\ x_2^{(n+1)} \end{pmatrix} = \left \{
\begin{array}{r c}
\frac{1}{x_1^n}\begin{pmatrix} 0 & 1 & 0 \\0 & -N(n) & 0 \\0 & 0& 1 \end{pmatrix} \begin{pmatrix} 1 \\ x_1^{(n)} \\ x_2^{(n)} \end{pmatrix} \, si \, j(n)=1\\
\frac{1}{x_1^n}\begin{pmatrix} 0 & 1 & 0 \\0 & 0 & 1 \\0 & -N(n) & 0 \end{pmatrix} \begin{pmatrix} 1 \\ x_1^{(n)} \\ x_2^{(n)} \end{pmatrix}\, si \, j(n)=2\\
\end{array}
\right .
$$
Soit $A_1^n=\begin{pmatrix} N(n) & 1 & 0 \\1 & 0 & 0 \\0 & 0 & 1 \end{pmatrix}$ et $A_2^n=\begin{pmatrix} N(n) & 0 & 1 \\1 & 0 & 0 \\0 & 1 & 0 \end{pmatrix}$ l'inverse des deux matrices ci-dessus. Nous posons de plus $S_n=A_{j(1)}^1 A_{j(2)}^2 ... A_{j(n)}^n$, alors nous avons:$$
\begin{pmatrix} 1 \\ x_1^{(0)} \\ x_2^{(0)} \end{pmatrix} = (\prod_{1 \leq i \leq n} x_1^{(i)})S_n \begin{pmatrix} 1 \\ x_1^{(n+1)} \\ x_2^{(n+1)} \end{pmatrix}
$$
Nous pouvons voir $S_n$ comme les coordonées d'une base dont les trois vecteurs formeraient un cône se convergeant vers la droite $D=t \times (1,x_1^{(0)},x_2^{(0)})$. \newline
Nous noterons également $S_n=\begin{pmatrix} a^{(n)} & a^{(n')} & a^{(n'')} \\ b_1^{(n)} & b_1^{(n')} & b_1^{(n'')} \\ b_2^{(n)} & b_2^{(n')} & b_2^{(n'')} \end{pmatrix}$ \newline

Nous avons alors $a^{(n+1)}=N(n)a^{(n)}+a^{(n')},a^{(n+1)'}=a^{(n)},a^{(n+1)''}=a^{(n'')}$ si $j(n)=1$, sinon $a^{(n+1)}=N(n)a^{(n)}+a^{(n')},a^{(n+1)'}=a^{(n'')},a^{(n+1)''}=a^{(n)}$. Ce résultat vaut aussi pour $b_1$ et $b_2$.

\section{Exposant de Lyapounov}

Nous pouvons aussi écrire $S_n=\begin{pmatrix} e_1^n & e_2^n & e_3^n\end{pmatrix}$.
 Nous avons alors $\lambda_1= lim_{n\to \infty} max \frac{1}{n}\|e_i^n\|$ le premier exposant de Lyapounov.\newline
 Définissons alors $\beta_1=e_2 \land e_3$, $\beta_2=e_3 \land e_1$ et $\beta_3=e_1 \land e_2$.
 Puis $\Lambda A_i \beta_j=A_i e_{j+1} \land A_i e_{j+2}$ et $\Lambda S^n=\Lambda A_{j(1)}^1  \Lambda A_{j(2)}^2 ... \Lambda A_{j(n)}^n$. \newline
 Nous avons alors $\beta_1^{n+1}=-\beta_2^{n},\beta_2^{n+1}=N(n) \beta_2^n-\beta_1^n,\beta_3^{n+1}=-\beta_3^n$
  si $j(n)=1$, sinon $\beta_1^{n+1}=\beta_2^{n},\beta_2^{n+1}=\beta_3,\beta_3^{n+1}=-N(n) \beta_2^n+\beta_1^n $
  Nous avons alors $\lambda_1 + \lambda_2= lim_{n\to \infty} max \frac{1}{n}\|\beta_i^n\|$ \newline
  Nous voyons alors qu'il suffit de montrer que $\|\beta^n\| \leq K \|e^n\|$ pour que $\lambda_2 \leq 0$ avec $K$ une constante positive. \newline
  Dans la suite nous poserons $s_n= max e_i^n$ et $\Delta_n=max \beta_i^n$. Nous vonlons donc montrer $\Delta_n \leq K s_n$
\section{Convergence}
\end{document}
